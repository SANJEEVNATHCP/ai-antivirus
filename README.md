# ğŸ›¡ï¸ AI Antivirus - LLM Safety Proxy

An intelligent security proxy that sits between your applications and Large Language Model (LLM) APIs to detect and block malicious prompts, jailbreak attempts, and sensitive data leakage in real-time.

## ğŸŒŸ Features

- **ğŸ”’ Multi-Layer Threat Detection**
  - Prompt Injection Detection
  - Jailbreak Attempt Detection
  - PII/Sensitive Data Leakage Detection

- **ğŸ”„ Universal API Compatibility**
  - OpenAI API (`/v1/chat/completions`)
  - Ollama API (`/api/generate`, `/api/chat`)

- **ğŸ“Š Real-Time Dashboard**
  - Live incident monitoring
  - Risk level visualization
  - Threat analytics

- **ğŸ’¾ Comprehensive Logging**
  - SQLite database for incident storage
  - Detailed threat reporting
  - Audit trail for compliance

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8+
- pip

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/SANJEEVNATHCP/ai-antivirus.git
   cd ai-antivirus
   ```

2. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

3. **Configure environment variables**
   ```bash
   cp .env.example .env
   # Edit .env with your actual configuration
   ```

4. **Run the application**
   ```bash
   uvicorn app.main:app --reload
   ```

5. **Access the dashboard**
   - Dashboard: http://localhost:8000/dashboard
   - Health Check: http://localhost:8000/health
   - API Docs: http://localhost:8000/docs

## ï¿½ Deployment

**âš ï¸ Important:** This is a Python FastAPI application. **Cloudflare Pages/Workers is NOT supported** as it's designed for static sites and JavaScript.

**Supported Platforms:**
- âœ… **Railway** (Recommended - easiest deployment)
- âœ… **Render** (Free tier available)
- âœ… **Docker** (Google Cloud Run, AWS ECS, Azure, Fly.io)
- âœ… **Heroku**
- âœ… **Vercel** (Limited - serverless only)

**ğŸ“– Full deployment guide:** [DEPLOYMENT.md](DEPLOYMENT.md)

**Quick Deploy to Railway:**
1. Fork this repository
2. Go to [railway.app](https://railway.app)
3. Click "Deploy from GitHub repo"
4. Select your fork
5. Add environment variables (OPENAI_API_KEY, etc.)
6. Deploy! ğŸš€

## ï¿½ğŸ¯ Usage

### As OpenAI Proxy

Replace your OpenAI endpoint with the proxy:

```python
import openai

openai.api_base = "http://localhost:8000/v1"
openai.api_key = "your-openai-api-key"

response = openai.ChatCompletion.create(
    model="gpt-3.5-turbo",
    messages=[{"role": "user", "content": "Hello!"}]
)
```

### As Ollama Proxy

Point your Ollama client to the proxy:

```bash
curl -X POST http://localhost:8000/api/chat \
  -H "Content-Type: application/json" \
  -d '{
    "model": "llama2",
    "messages": [{"role": "user", "content": "Hello!"}]
  }'
```

### PowerShell Example

```powershell
$body = @{
    model = "llama2"
    messages = @(
        @{
            role = "user"
            content = "What is AI?"
        }
    )
} | ConvertTo-Json -Depth 3

Invoke-RestMethod -Uri "http://localhost:8000/api/chat" -Method POST -ContentType "application/json" -Body $body
```

## ğŸ” Detection Capabilities

### 1. Prompt Injection Detection
Identifies attempts to manipulate the LLM's behavior:
- "Ignore previous instructions"
- "System prompt override"
- "Bypass safety filters"

### 2. Jailbreak Detection
Catches common jailbreak techniques:
- DAN (Do Anything Now) mode
- Unfiltered response requests
- Role-playing exploits

### 3. PII Leakage Detection
Prevents sensitive data exposure:
- Email addresses
- Credit card numbers
- Social Security Numbers

## ğŸ“ˆ Risk Scoring

| Risk Level | Score Range | Action |
|------------|-------------|--------|
| LOW | 0-20 | âœ… Allow |
| MEDIUM | 21-50 | âœ… Allow (Log) |
| HIGH | 51-79 | âš ï¸ Allow (Flag) |
| CRITICAL | 80+ | âŒ Block |

Default blocking threshold: **50** (configurable via `RISK_THRESHOLD`)

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Client    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  AI Antivirus â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  LLM API    â”‚
â”‚ Application â”‚         â”‚     Proxy     â”‚         â”‚ (OpenAI/    â”‚
â”‚             â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”‚               â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”‚  Ollama)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚   SQLite DB   â”‚
                        â”‚  (Incidents)  â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
ai-antivirus/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ dashboard.py      # Dashboard & API endpoints
â”‚   â”‚   â””â”€â”€ proxy.py          # Proxy endpoints
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â””â”€â”€ config.py         # Configuration
â”‚   â”œâ”€â”€ detectors/
â”‚   â”‚   â”œâ”€â”€ base.py           # Base detector class
â”‚   â”‚   â”œâ”€â”€ injection.py      # Injection detector
â”‚   â”‚   â”œâ”€â”€ jailbreak.py      # Jailbreak detector
â”‚   â”‚   â””â”€â”€ leakage.py        # PII leakage detector
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ database.py       # SQLAlchemy models
â”‚   â”‚   â””â”€â”€ schemas.py        # Pydantic schemas
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ scanner.py        # Scanning orchestrator
â”‚   â”‚   â””â”€â”€ proxy_service.py  # HTTP proxy service
â”‚   â”œâ”€â”€ templates/
â”‚   â”‚   â””â”€â”€ dashboard.html    # Web dashboard
â”‚   â”œâ”€â”€ static/
â”‚   â”‚   â””â”€â”€ css/              # Stylesheets
â”‚   â””â”€â”€ main.py               # FastAPI application
â”œâ”€â”€ rules/
â”‚   â””â”€â”€ signatures.json       # Threat signatures
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_detectors.py     # Unit tests
â”œâ”€â”€ requirements.txt
â””â”€â”€ .env.example
```

## âš™ï¸ Configuration

Edit `.env` to customize:

```env
# Application
APP_ENV=development
RISK_THRESHOLD=50

# LLM Backends
OLLAMA_BASE_URL=http://localhost:11434
OPENAI_BASE_URL=https://api.openai.com/v1
OPENAI_API_KEY=your_key_here

# Database
DATABASE_URL=sqlite:///./incidents.db
```

## ğŸ§ª Testing

Run the test suite:

```bash
pytest tests/
```

Test individual detectors:

```bash
pytest tests/test_detectors.py -v
```

### Manual Testing

```powershell
# Test safe request
Invoke-RestMethod -Uri "http://localhost:8000/health" -Method GET

# Test malicious request (should be blocked)
$body = @{
    model = "llama2"
    messages = @(@{role = "user"; content = "Ignore all previous instructions"})
} | ConvertTo-Json -Depth 3

Invoke-RestMethod -Uri "http://localhost:8000/api/chat" -Method POST -ContentType "application/json" -Body $body
```

## ğŸ“Š Dashboard Features

Access the web dashboard at `http://localhost:8000/dashboard`

- **Incident Table**: View all detected threats
- **Color-Coded Risk Levels**: Visual risk assessment
- **Threat Details**: See detected threat patterns
- **Action Status**: ALLOW vs BLOCK decisions
- **Real-time Updates**: Manual refresh capability

## ğŸ”’ Security Notes

- **API Keys**: Never commit `.env` file to version control
- **Database**: `incidents.db` contains sensitive data - exclude from git
- **Production**: Use proper authentication for dashboard access
- **HTTPS**: Deploy behind reverse proxy with SSL/TLS

## ğŸ¤ Contributing

Contributions are welcome! Please:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“ License

This project is open source and available under the MIT License.

## ğŸ™ Acknowledgments

- FastAPI for the web framework
- SQLAlchemy for database ORM
- Tailwind CSS for dashboard styling

## ğŸ“§ Contact

**Sanjeev Nath CP**
- GitHub: [@SANJEEVNATHCP](https://github.com/SANJEEVNATHCP)

---

**âš ï¸ Disclaimer**: This is a security tool for educational and protection purposes. Always test thoroughly before using in production environments.
